{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* __Student name__: Hannah Kwirikia\n",
    "* __Student pace__: full time\n",
    "* __Scheduled project review date/time__: 20th Nov.2022/ 11:59PM\n",
    "* __Instructor name__: Mark Tiba \n",
    "* __Blog post URL__:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft's Movie Market Analysis - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To find out what types of films are currently doing the best at the box office.\n",
    "\n",
    "- To find out factors affecting film performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the steps I will follow for my research:\n",
    "    \n",
    "1. Import data\n",
    "2. Unzip data\n",
    "3. Merge datasets\n",
    "4. Data cleaning\n",
    "4. Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "\n",
    "1. What films have highest domestic gross?\n",
    "2. What are the top studios by no. of movies?\n",
    "3. Does length affect the grossing?\n",
    "4. Which movies have the highest rating?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses two data files namely:\n",
    "- __im.db.zip__ extracted from __Box Office__\n",
    "- __boom.movie_gross.csv.gz__ extracted from __IMDB__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd C:\\\\Users\\\\Win 10 Pro\\\\Desktop\\\\dsc-phase-1-project-v2-4\\\\zippedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Unzip First Dataset (im.db.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to unzip IMDB file\n",
    "import zipfile\n",
    "with zipfile.ZipFile('im.db.zip', 'r') as my_zip:\n",
    "    my_zip.extractall('files') # the unzipped files are now in a folder named files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:\\\\Users\\\\Win 10 Pro\\\\Desktop\\\\dsc-phase-1-project-v2-4\\\\zippedData\\\\files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view list of tables\n",
    "conn = sqlite3.connect('im.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT name FROM sqlite_master WHERE type = 'table';\"\"\")\n",
    "table_names = cur.fetchall()\n",
    "table_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tables for the 'movie_basics' and 'movie_ratings' are the most important. We will look at them below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### movie_basics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#to view the movie_basics table\n",
    "movie_basics = pd.read_sql(\"\"\"SELECT * FROM movie_basics;\"\"\", conn )\n",
    "movie_basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### movie_ratings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view the movie_ratings table\n",
    "movie_ratings = pd.read_sql(\"\"\"SELECT * FROM movie_ratings;\"\"\", conn )\n",
    "movie_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging movie_basics and movie_ratings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge movie_basics and movie_ratings tables\n",
    "merged_movies = pd.merge(left=movie_basics, right=movie_ratings, on='movie_id')\n",
    "merged_movies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Unzip Second Dataset(boom.movie_gross.csv.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:\\\\Users\\\\Win 10 Pro\\\\Desktop\\\\dsc-phase-1-project-v2-4\\\\zippedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip .gz file\n",
    "import gzip\n",
    "with gzip.open('bom.movie_gross.csv.gz') as f:\n",
    "\n",
    "    bom_df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preview the data \n",
    "bom_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rename title column to primary_title to enable merging\n",
    "bom_df.rename(columns = {'title':'primary_title'}, inplace = True)\n",
    "bom_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge First Data with Second Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#merge first data with second data\n",
    "df = pd.merge(left = merged_movies, right = bom_df, on = 'primary_title')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn more about the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merged data has 3027 rows and 12 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#summary of the data overview\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "The data cleaning process will entail three main steps:\n",
    "- looking for duplicates\n",
    "- looking for missing values\n",
    "- check outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for any duplicates\n",
    "\n",
    "Below I defined a function to detect duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicated entries\n",
    "def identify_duplicates(data):\n",
    "    \"\"\"A function to identify any duplicates\"\"\"\n",
    "    # identify the duplicates \n",
    "    # empty list to store Bool results from duplicated\n",
    "    duplicates = []\n",
    "    for i in data.duplicated():\n",
    "        duplicates.append(i)\n",
    "    # identify if there is any duplicates. \n",
    "    duplicates_set = set(duplicates) \n",
    "    if (len(duplicates_set) == 1):\n",
    "        print(\"The Data has no duplicates\")\n",
    "    else:\n",
    "        no_true = 0\n",
    "        for val in duplicates:\n",
    "            if (val == True):\n",
    "                no_true += 1\n",
    "        # percentage of the data represented by duplicates \n",
    "        duplicates_percentage = np.round(((no_true / len(data)) * 100), 3)\n",
    "        print(f\"The Data has {no_true} duplicated rows.\\nThis constitutes {duplicates_percentage}% of the data set.\") \n",
    "\n",
    "\n",
    "\n",
    "identify_duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for Duplicates in the Primary Key column\n",
    "Columns that have unique details such as the movie_id should not contain any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_column_duplicates(data, column):\n",
    "    \"\"\"handling duplicates in unique column\"\"\"\n",
    "    # empty list to store the duplicate bools\n",
    "    duplicates = []\n",
    "    for i in data[column].duplicated():\n",
    "        duplicates.append(i)\n",
    "    \n",
    "    # identify if there are any duplicates\n",
    "    duplicates_set = set(duplicates)\n",
    "    if (len(duplicates_set) == 1):\n",
    "        print(f\"The column {column.title()} has no duplicates\")\n",
    "    else:\n",
    "        no_true = 0\n",
    "        for val in duplicates:\n",
    "            if (val == True):\n",
    "                no_true += 1\n",
    "        # percentage of the data represented by duplicates \n",
    "        duplicates_percentage = np.round(((no_true / len(data)) * 100), 3)\n",
    "        print(f\"The column {column.title()} has {no_true} duplicated rows.\\nThis constitutes {duplicates_percentage}% of the data set.\")\n",
    "\n",
    "\n",
    "unique_column_duplicates(df, \"movie_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the movie_id are our unique identifiers,  are unique. Thus we need to remove any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling the unique column duplicates \n",
    "def remove_unique_column_duplicates(data, column):\n",
    "    \"\"\"Simple Function to remove duplicated rows\"\"\"\n",
    "    data.drop_duplicates(subset=column, keep=\"first\", inplace=True)\n",
    "    # confirm if the duplicated rows have been removed\n",
    "    confirm = unique_column_duplicates(df, \"movie_id\")\n",
    "\n",
    "    return confirm \n",
    "\n",
    "\n",
    "remove_unique_column_duplicates(df, \"movie_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicates along the movie_id column have now been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify missing \n",
    "def identify_missing_values(data):\n",
    "    \"\"\"Identify is the data has missing values\"\"\"\n",
    "    # identify if data has missing values(data.isnull().any())\n",
    "    # empty dict to store missing values\n",
    "    missing = []\n",
    "    for i in data.isnull().any():\n",
    "        # add the bool values to empty list \n",
    "        missing.append(i)\n",
    "    # covert list to set (if data has missing value, the list should have true and false)\n",
    "    missing_set = set(missing)\n",
    "    if (len(missing_set) == 1):\n",
    "        out = print(\"The Data has no missing values\")\n",
    "    else:\n",
    "        out = print(\"The Data has missing values.\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "identify_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#identify missing values\n",
    "def missing_values(data):\n",
    "    \"\"\"A simple function to identify data has missing values\"\"\"\n",
    "    # identify the total missing values per column\n",
    "    # sort in order \n",
    "    miss = data.isnull().sum().sort_values(ascending = False)\n",
    "\n",
    "    # calculate percentage of the missing values\n",
    "    percentage_miss = (data.isnull().sum() / len(data)).sort_values(ascending = False)\n",
    "\n",
    "    # store in a dataframe \n",
    "    missing = pd.DataFrame({\"Missing Values\": miss, \"Percentage(%)\": percentage_miss})\n",
    "\n",
    "    # remove values that are missing \n",
    "    missing.drop(missing[missing[\"Percentage(%)\"] == 0].index, inplace = True)\n",
    "\n",
    "    return missing\n",
    "\n",
    "\n",
    "missing_data = missing_values(df)\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_missing(data):\n",
    "    \"\"\"Graphically represent the missing values\"\"\"\n",
    "    fig, axes = plt.subplots(figsize = (6, 3))\n",
    "\n",
    "    sns.barplot(x = data.index , y = data[\"Missing Values\"]) \n",
    "    plt.xlabel(\"Columns\", fontdict={\"color\": \"black\",  \"size\": 15}) \n",
    "    plt.xticks(rotation = '60') \n",
    "    plt.ylabel(\"Missing Values\", fontdict={\"color\": \"black\",  \"size\": 15}) \n",
    "    plt.title(\"Missing Values per Column\", fontsize = 18)\n",
    "    plt.show()\n",
    "\n",
    "    # save the plot \n",
    "    fig.savefig(\"missing.png\")\n",
    "\n",
    "\n",
    "graph_missing(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 3 rows missing in the studio, we can drop those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['studio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 7 row missing in the genre, we can drop that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domestic_gross column has less than 1% (22 values) missing values. Thus, we will replace the missing value by the mean domestic_gross income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values in domestic_gross with mean\n",
    "df['domestic_gross'] = df['domestic_gross'].fillna(df['domestic_gross'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runtime_minutes column also has less than 1%(47 values) of missing values. Thus, we will replace the missing value by the mean runtime_minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values in runtime_minutes with mean\n",
    "df['runtime_minutes'] = df['runtime_minutes'].fillna(df['runtime_minutes'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The foreign_gross column  has the highest number of missing values at about 40%. Thus, we drop that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'foreign_gross', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Funtion to Detect Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQR_outliers(data, column):\n",
    "    \"\"\"Simple function to identify and remove outliers using IQR\"\"\"\n",
    "    # get Q1 and Q2\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    # calculate IQR\n",
    "    IQR = Q3-Q1\n",
    "    # identify ouliers (returns True if an outlier)\n",
    "    out = ((data[column]<(Q1-1.5*IQR)) | (data[column]>(Q3+1.5*IQR)))\n",
    "\n",
    "    # identify the outlier using index\n",
    "    outliers_list = list(out[out==True].index)\n",
    "    # identify the actual outliers using index\n",
    "    outliers = []\n",
    "    for val in outliers_list:\n",
    "        outliers.append(data[column][val])\n",
    "\n",
    "    \n",
    "    return outliers, Q1, Q3, IQR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. domestic_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domestic_gross_outliers = IQR_outliers(df, \"domestic_gross\")\n",
    "domestic_gross_outliers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQR_outliers(data, column):\n",
    "    \"\"\"Simple function to identify and remove outliers using IQR\"\"\"\n",
    "    # get Q1 and Q2\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    # calculate IQR\n",
    "    IQR = Q3-Q1\n",
    "    # identify ouliers (returns True if an outlier)\n",
    "    out = ((data[column]<(Q1-1.5*IQR)) | (data[column]>(Q3+1.5*IQR)))\n",
    "\n",
    "    # identify the outlier using index\n",
    "    outliers_list = list(out[out==True].index)\n",
    "    # identify the actual outliers using index\n",
    "    outliers = []\n",
    "    for val in outliers_list:\n",
    "        outliers.append(data[column][val])\n",
    "\n",
    "    \n",
    "    return outliers, Q1, Q3, IQR\n",
    "\n",
    "\n",
    "domestic_gross_outliers = IQR_outliers(df, \"domestic_gross\")\n",
    "domestic_gross_outliers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domestic_gross_outliers are possible values thus we will leave them as they are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. start year\n",
    "\n",
    "The start year has no outliers as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year_outliers = IQR_outliers(df, \"start_year\")\n",
    "start_year_outliers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a box plot to identify outliers\n",
    "\n",
    "sns.boxplot(data=df, x=\"start_year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Runtime minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_minutes_outliers = IQR_outliers(df, \"runtime_minutes\")\n",
    "runtime_minutes_outliers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runtime_minutes_outliers are possible values thus we will leave them as they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. averagerating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averagerating_outliers = IQR_outliers(df, \"averagerating\")\n",
    "averagerating_outliers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The averagerating_outliers are possible values thus we will leave them as they are. This is further backed by the box plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. numvotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numvotes_outliers = IQR_outliers(df, \"numvotes\")\n",
    "numvotes_outliers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numvotes_outliers are possible values thus we will leave them as they are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_outliers = IQR_outliers(df, \"year\")\n",
    "year_outliers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a box plot to identify outliers\n",
    "\n",
    "sns.boxplot(data=df, x=\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The start year has no outliers as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1: What Movie Genres Have the Highest Domestic Gross?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting to find movies with highest domestic_gross per genre\n",
    "gross_by_genre = df.sort_values('domestic_gross',ascending = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_by_genre.loc[:, [\"primary_title\", \"genres\", \"domestic_gross\", \"studio\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gross_by_genre['genres'][:20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = gross_by_genre['domestic_gross'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = gross_by_genre['genres'].values, y = gross_by_genre['domestic_gross'][:20], data = gross_by_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = gross_by_genre['genres'].values, y = gross_by_genre['domestic_gross'][:20], hue = gross_by_genre['studio'][:20], data =gross_by_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting the data above\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(20,12))\n",
    "\n",
    "ax1 = sns.barplot(data = gross_by_genre, x = 'genres', y = 'domestic_gross', ax = ax1, dodge=False)\n",
    "\n",
    "labels = list(gross_by_genere['genres']\n",
    "ax1.set_title('Genre vs Domestic Gross', fontsize=20)\n",
    "ax1.set_xlabel(\"Movie Genres\",fontsize=18)\n",
    "ax1.set_ylabel(\"Domestic Gross\", fontsize=18)\n",
    "ax1.legend(title='Studio', fontsize=18, loc=1)\n",
    "ax1.set_ylim(500)\n",
    "ax1.set_xlim(20)\n",
    "ax1.set_xticklabels(labels = x, rotation = 60,fontsize=14)\n",
    "ax1.set_yticklabels(labels = y,fontsize=14)\n",
    "\n",
    "ax1.set_xticklabels(labels = x, rotation = 90)\n",
    "ax1.set_ylim(6.5, 8.5)\n",
    "fig.savefig('Genre vs Domestic - Gross.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ2: Do Highly Rated Movies Earn High Domestic Gross?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting to find movies with highest domestic_gross per genre\n",
    "highly_rated_gross = gross_by_genre.sort_values('averagerating', ascending = False).reset_index(drop=True)\n",
    "highly_rated_gross.loc[:, [\"primary_title\",\"averagerating\", \"genres\", \"domestic_gross\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ#: Do longer movies translate to higher income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask and Answer Question\n",
    "\n",
    "Is domestic gross capital or foreign gross higher\n",
    "does year affect gross and foreign gross\n",
    "studio vs gross income\n",
    "What are the top studios by no. of titles?\n",
    "WHat are the top studios by gross income? Domestic and foreign?\n",
    "most studios have very few titles\n",
    "\n",
    "most movies are around 100 minutes long with a average of 108 minutes,\n",
    "does the distribution of depended on movie type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
